---
title: Multi-Modal Language Model from scratch (Pali-Gemma)
layout: project 
year: experiment replication
project-url: https://colab.research.google.com/drive/1DE0TG85vTJQthlFvJ-B8Q0n3CxH2R0qD?usp=sharing
excerpt: Coded a multi-modal model for visual question answering as in this paper (https://arxiv.org/pdf/2407.07726). The authors used SigLIP vision encoder with the decoder-only based Gemma:2b model.
project-image: multi_modal_paligemma.png
tags: [Pytorch, 3D-vision]
comments: false
---
